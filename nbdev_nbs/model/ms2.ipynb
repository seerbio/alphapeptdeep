{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model.ms2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS2 prediction\n",
    "\n",
    "pDeepModel and its interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from typing import List, Tuple, IO\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from alphabase.peptide.fragment import (\n",
    "    init_fragment_by_precursor_dataframe, \n",
    "    update_sliced_fragment_dataframe, \n",
    "    get_sliced_fragment_dataframe, \n",
    "    get_charged_frag_types\n",
    ")\n",
    "\n",
    "from peptdeep.utils import get_available_device\n",
    "\n",
    "from peptdeep.model.featurize import (\n",
    "    get_batch_aa_indices, parse_instrument_indices,\n",
    "    mod_feature_size\n",
    ")\n",
    "\n",
    "from peptdeep.settings import (\n",
    "    global_settings as settings,\n",
    "    model_const\n",
    ")\n",
    "\n",
    "import peptdeep.model.model_interface as model_interface\n",
    "import peptdeep.model.building_block as building_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ModelMS2Transformer(torch.nn.Module):\n",
    "    \"\"\"Transformer model for MS2 prediction\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_frag_types : int\n",
    "        Total number of fragment types of a fragmentation position to predict\n",
    "\n",
    "    num_modloss_types : int, optional\n",
    "        Number of fragment types of a fragmentation position to predict, by default 0\n",
    "\n",
    "    mask_modloss : bool, optional\n",
    "        If True, the modloss layer will be disabled, by default True\n",
    "\n",
    "    dropout : float, optional\n",
    "        Dropout, by default 0.1\n",
    "\n",
    "    nlayers : int, optional\n",
    "        Number of transformer layer, by default 4\n",
    "\n",
    "    hidden : int, optional\n",
    "        Hidden layer size, by default 256\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        num_frag_types:int,\n",
    "        num_modloss_types:int=0,\n",
    "        mask_modloss:bool=True,\n",
    "        dropout:float=0.1,\n",
    "        nlayers:int=4,\n",
    "        hidden:int=256,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self._num_modloss_types = num_modloss_types\n",
    "        self._num_non_modloss = num_frag_types-num_modloss_types\n",
    "        self._mask_modloss = mask_modloss\n",
    "        if num_modloss_types == 0:\n",
    "            self._mask_modloss = True\n",
    "\n",
    "        meta_dim = 8\n",
    "        self.input_nn = building_block.Input_26AA_Mod_PositionalEncoding(hidden-meta_dim)\n",
    "\n",
    "        self.meta_nn = building_block.Meta_Embedding(meta_dim)\n",
    "\n",
    "        self.hidden_nn = building_block.Hidden_Transformer(\n",
    "            hidden, nlayers=nlayers, dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.output_nn = building_block.Decoder_Linear(\n",
    "            hidden,\n",
    "            self._num_non_modloss,\n",
    "        )\n",
    "        \n",
    "        if num_modloss_types > 0:\n",
    "            # for transfer learning of modloss frags\n",
    "            self.modloss_nn = torch.nn.ModuleList([\n",
    "                building_block.Hidden_Transformer(\n",
    "                    hidden, nlayers=1, dropout=dropout\n",
    "                ),\n",
    "                building_block.Decoder_Linear(\n",
    "                    hidden, num_modloss_types,\n",
    "                ),\n",
    "            ])\n",
    "        else:\n",
    "            self.modloss_nn = None\n",
    "\n",
    "    def forward(self,\n",
    "        aa_indices,\n",
    "        mod_x,\n",
    "        charges:torch.Tensor,\n",
    "        NCEs:torch.Tensor,\n",
    "        instrument_indices,\n",
    "    ):\n",
    "\n",
    "        in_x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1,in_x.size(1),1)\n",
    "        in_x = torch.cat((in_x, meta_x),2)\n",
    "\n",
    "        hidden_x = self.hidden_nn(in_x)\n",
    "        hidden_x = self.dropout(hidden_x+in_x*0.2)\n",
    "\n",
    "        out_x = self.output_nn(\n",
    "            hidden_x\n",
    "        )\n",
    "\n",
    "        if self._num_modloss_types > 0:\n",
    "            if self._mask_modloss:\n",
    "                out_x = torch.cat((out_x, torch.zeros(\n",
    "                    *out_x.size()[:2],self._num_modloss_types,\n",
    "                    device=in_x.device\n",
    "                )), 2)\n",
    "            else:\n",
    "                modloss_x = self.modloss_nn[0](\n",
    "                    in_x\n",
    "                ) + hidden_x\n",
    "                modloss_x = self.modloss_nn[-1](\n",
    "                    modloss_x\n",
    "                )\n",
    "                out_x = torch.cat((\n",
    "                    out_x, modloss_x\n",
    "                ),2)\n",
    "\n",
    "        return out_x[:,3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0770,  0.0803],\n",
       "         [-0.0555,  0.0817],\n",
       "         [-0.0159, -0.0468],\n",
       "         [ 0.0321, -0.2095],\n",
       "         [ 0.0602, -0.3224],\n",
       "         [ 0.0463, -0.3438],\n",
       "         [-0.0423, -0.4887]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "torch.manual_seed(1337)\n",
    "sequence = 'AAAAAAAA'\n",
    "max_instrument_num = 4\n",
    "aa_indices = torch.LongTensor(get_batch_aa_indices([sequence]))\n",
    "charges = torch.tensor([[2]])\n",
    "instrument_indices = torch.LongTensor([1])\n",
    "NCEs = torch.tensor([[0.3]])\n",
    "mod_x = torch.zeros((1, aa_indices.size(1), mod_feature_size))\n",
    "msms_model = ModelMS2Transformer(2, 1, mask_modloss=False)\n",
    "msms_model.eval()\n",
    "out = msms_model(aa_indices, mod_x, charges, NCEs, instrument_indices)\n",
    "assert out.size() == (1,len(sequence)-1,2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1752, 0.0000],\n",
       "         [0.1774, 0.0000],\n",
       "         [0.1738, 0.0000],\n",
       "         [0.1604, 0.0000],\n",
       "         [0.1426, 0.0000],\n",
       "         [0.1178, 0.0000],\n",
       "         [0.0648, 0.0000]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "msms_model = ModelMS2Transformer(2, 1, mask_modloss=True)\n",
    "msms_model.eval()\n",
    "out = msms_model(aa_indices, mod_x, charges, NCEs, instrument_indices)\n",
    "assert out.size() == (1,len(sequence)-1,2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModelMS2Bert(torch.nn.Module):\n",
    "    \"\"\"Using HuggingFace's BertEncoder for MS2 prediction\"\"\"\n",
    "    def __init__(self,\n",
    "        num_frag_types,\n",
    "        num_modloss_types=0,\n",
    "        mask_modloss=True,\n",
    "        dropout=0.1,\n",
    "        nlayers=4,\n",
    "        hidden=256,\n",
    "        output_attentions=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self._num_modloss_types = num_modloss_types\n",
    "        self._num_non_modloss = num_frag_types-num_modloss_types\n",
    "        self._mask_modloss = mask_modloss\n",
    "        if num_modloss_types == 0:\n",
    "            self._mask_modloss = True\n",
    "\n",
    "        meta_dim = 8\n",
    "        self.input_nn = building_block.Input_26AA_Mod_PositionalEncoding(hidden-meta_dim)\n",
    "\n",
    "        self.meta_nn = building_block.Meta_Embedding(meta_dim)\n",
    "\n",
    "        self._output_attentions = output_attentions\n",
    "        self.hidden_nn = building_block.Hidden_HFace_Transformer(\n",
    "            hidden, nlayers=nlayers, dropout=dropout,\n",
    "            output_attentions=output_attentions\n",
    "        )\n",
    "\n",
    "        self.output_nn = building_block.Decoder_Linear(\n",
    "            hidden,\n",
    "            self._num_non_modloss,\n",
    "        )\n",
    "        \n",
    "        if num_modloss_types > 0:\n",
    "            # for transfer learning of modloss frags\n",
    "            self.modloss_nn = torch.nn.ModuleList([\n",
    "                building_block.Hidden_HFace_Transformer(\n",
    "                    hidden, nlayers=1, dropout=dropout,\n",
    "                    output_attentions=output_attentions\n",
    "                ),\n",
    "                building_block.Decoder_Linear(\n",
    "                    hidden, num_modloss_types,\n",
    "                ),\n",
    "            ])\n",
    "        else:\n",
    "            self.modloss_nn = None\n",
    "\n",
    "    @property\n",
    "    def output_attentions(self):\n",
    "        return self._output_attentions\n",
    "        \n",
    "    @output_attentions.setter\n",
    "    def output_attentions(self, val:bool):\n",
    "        self._output_attentions = val\n",
    "        self.hidden_nn.output_attentions = val\n",
    "        self.modloss_nn[0].output_attentions = val\n",
    "\n",
    "    def forward(self,\n",
    "        aa_indices,\n",
    "        mod_x,\n",
    "        charges:torch.Tensor,\n",
    "        NCEs:torch.Tensor,\n",
    "        instrument_indices,\n",
    "    ):\n",
    "\n",
    "        in_x = self.dropout(self.input_nn(\n",
    "            aa_indices, mod_x\n",
    "        ))\n",
    "        meta_x = self.meta_nn(\n",
    "            charges, NCEs, instrument_indices\n",
    "        ).unsqueeze(1).repeat(1,in_x.size(1),1)\n",
    "        in_x = torch.cat((in_x, meta_x),2)\n",
    "\n",
    "        hidden_x = self.hidden_nn(in_x)\n",
    "        if self.output_attentions:\n",
    "            self.attentions = hidden_x[1]\n",
    "        else:\n",
    "            self.attentions = None\n",
    "        hidden_x = self.dropout(hidden_x[0]+in_x*0.2)\n",
    "\n",
    "        out_x = self.output_nn(\n",
    "            hidden_x\n",
    "        )\n",
    "\n",
    "        self.modloss_attentions = None\n",
    "        if self._num_modloss_types > 0:\n",
    "            if self._mask_modloss:\n",
    "                out_x = torch.cat((out_x, torch.zeros(\n",
    "                    *out_x.size()[:2],self._num_modloss_types,\n",
    "                    device=in_x.device\n",
    "                )), 2)\n",
    "            else:\n",
    "                modloss_x = self.modloss_nn[0](\n",
    "                    in_x\n",
    "                )\n",
    "                if self.output_attentions:\n",
    "                    self.modloss_attentions = modloss_x[-1]\n",
    "                modloss_x = modloss_x[0] + hidden_x\n",
    "                modloss_x = self.modloss_nn[-1](\n",
    "                    modloss_x\n",
    "                )\n",
    "                out_x = torch.cat((\n",
    "                    out_x, modloss_x\n",
    "                ),2)\n",
    "\n",
    "        return out_x[:,3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([1, 8, 10, 10]), 1, torch.Size([1, 8, 10, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "torch.manual_seed(1337)\n",
    "sequence = 'AAAAAAAA'\n",
    "max_instrument_num = 4\n",
    "aa_indices = torch.LongTensor(get_batch_aa_indices([sequence]))\n",
    "charges = torch.tensor([[2]])\n",
    "instrument_indices = torch.LongTensor([1])\n",
    "NCEs = torch.tensor([[0.3]])\n",
    "mod_x = torch.zeros((1, aa_indices.size(1), mod_feature_size))\n",
    "msms_model = ModelMS2Bert(2, 1, mask_modloss=False)\n",
    "msms_model.eval()\n",
    "out = msms_model(aa_indices, mod_x, charges, NCEs, instrument_indices)\n",
    "assert out.size() == (1,len(sequence)-1,2)\n",
    "msms_model.output_attentions = True\n",
    "msms_model(aa_indices, mod_x, charges, NCEs, instrument_indices)\n",
    "(\n",
    "    len(msms_model.attentions), msms_model.attentions[0].size(),\n",
    "    len(msms_model.modloss_attentions), msms_model.modloss_attentions[0].size()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ModelMS2pDeep(torch.nn.Module):\n",
    "    \"\"\"LSTM model for MS2 prediction similar to pDeep series\"\"\"\n",
    "    def __init__(self,\n",
    "        num_frag_types,\n",
    "        num_modloss_types=0,\n",
    "        mask_modloss=True,\n",
    "        dropout=0.1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self._num_modloss_types = num_modloss_types\n",
    "        self._num_non_modloss = num_frag_types-num_modloss_types\n",
    "        self._mask_modloss = mask_modloss\n",
    "        if num_modloss_types == 0:\n",
    "            self._mask_modloss = True\n",
    "\n",
    "        BiRNN = True\n",
    "        hidden=512\n",
    "        hidden_rnn_layer=2\n",
    "\n",
    "        self.input_nn = building_block.InputAALSTM_cat_Meta(hidden)\n",
    "\n",
    "        self.hidden_nn = building_block.SeqLSTM(\n",
    "            hidden, hidden, rnn_layer=hidden_rnn_layer, \n",
    "            bidirectional=BiRNN\n",
    "        )\n",
    "\n",
    "        self.output_nn = building_block.OutputLSTM_cat_Meta(\n",
    "            hidden,\n",
    "            self._num_non_modloss,\n",
    "        )\n",
    "\n",
    "        if num_modloss_types:\n",
    "            # for transfer learning of modloss frags\n",
    "            self.modloss_nn = torch.nn.ModuleList([\n",
    "                building_block.SeqLSTM(\n",
    "                    hidden, hidden, \n",
    "                    rnn_layer=1, bidirectional=BiRNN\n",
    "                ),\n",
    "                building_block.SeqLSTM(\n",
    "                    hidden, num_modloss_types,\n",
    "                    rnn_layer=1, bidirectional=False\n",
    "                ),\n",
    "            ])\n",
    "        else:\n",
    "            self.modloss_nn = None\n",
    "\n",
    "    def forward(self,\n",
    "        aa_indices,\n",
    "        mod_x,\n",
    "        charges:torch.Tensor,\n",
    "        NCEs:torch.Tensor,\n",
    "        instrument_indices,\n",
    "    ):\n",
    "\n",
    "        in_x = self.input_nn(\n",
    "            aa_indices, mod_x, \n",
    "            charges, NCEs, instrument_indices\n",
    "        )\n",
    "        in_x = self.dropout(in_x)\n",
    "\n",
    "        hidden_x = self.hidden_nn(in_x)\n",
    "        hidden_x = self.dropout(hidden_x)\n",
    "\n",
    "        out_x = self.output_nn(\n",
    "            hidden_x, \n",
    "            charges, NCEs, instrument_indices\n",
    "        )\n",
    "\n",
    "        # modloss is mainly only for Phospho@S/T\n",
    "        if self._num_modloss_types > 0:\n",
    "            if self._mask_modloss:\n",
    "                out_x = torch.cat((out_x, torch.zeros(\n",
    "                    *out_x.size()[:2],self._num_modloss_types,\n",
    "                    device=in_x.device\n",
    "                )), 2)\n",
    "            else:\n",
    "                modloss_x = self.modloss_nn[0](\n",
    "                    in_x\n",
    "                ) + hidden_x\n",
    "                modloss_x = self.modloss_nn[-1](\n",
    "                    modloss_x\n",
    "                )\n",
    "                out_x = torch.cat((\n",
    "                    out_x, modloss_x\n",
    "                ),2)\n",
    "\n",
    "        return out_x[:,3:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2764, -0.3128],\n",
       "         [-0.2750, -0.3725],\n",
       "         [-0.2712, -0.4207],\n",
       "         [-0.2656, -0.4509],\n",
       "         [-0.2563, -0.4414],\n",
       "         [-0.2405, -0.4114],\n",
       "         [-0.2136, -0.3333]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "sequence = 'ACDEFGIK'\n",
    "max_instrument_num = 4\n",
    "aa_indices = torch.LongTensor(get_batch_aa_indices([sequence]))\n",
    "charges = torch.tensor([[2]])\n",
    "instrument_indices = torch.LongTensor([1])\n",
    "NCEs = torch.tensor([[0.3]])\n",
    "mod_x = torch.zeros((1, aa_indices.size(1), mod_feature_size))\n",
    "msms_model = ModelMS2pDeep(2, 1, mask_modloss=False)\n",
    "msms_model.eval()\n",
    "out = msms_model(aa_indices, mod_x, charges, NCEs, instrument_indices)\n",
    "assert out.size() == (1,len(sequence)-1,2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IntenAwareLoss(torch.nn.Module):\n",
    "    \"\"\"Loss weighted by intensity for MS2 models\"\"\"\n",
    "    def __init__(self, base_weight=0.2):\n",
    "        super().__init__()\n",
    "        self.w = base_weight\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        return torch.mean(\n",
    "            (target+self.w)*torch.abs(target-pred)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "max_instrument_num = model_const['max_instrument_num']\n",
    "frag_types = settings['model']['frag_types']\n",
    "max_frag_charge = settings['model']['max_frag_charge']\n",
    "num_ion_types = len(frag_types)*max_frag_charge\n",
    "\n",
    "class pDeepModel(model_interface.ModelInterface):\n",
    "    \"\"\"\n",
    "    `ModelInterface` for MS2 prediction models\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        charged_frag_types = get_charged_frag_types(\n",
    "            frag_types, max_frag_charge\n",
    "        ),\n",
    "        dropout=0.1,\n",
    "        mask_modloss=True,\n",
    "        modloss_type='modloss',\n",
    "        model_class:torch.nn.Module=ModelMS2Bert,\n",
    "        device:str='gpu',\n",
    "        **kwargs, #model params\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.charged_frag_types = charged_frag_types\n",
    "        self._get_modloss_frags(modloss_type)\n",
    "\n",
    "        self.charge_factor = 0.1\n",
    "        self.NCE_factor = 0.01\n",
    "        self.build(\n",
    "            model_class, \n",
    "            num_frag_types = len(self.charged_frag_types),\n",
    "            num_modloss_types = len(self._modloss_frag_types),\n",
    "            mask_modloss=mask_modloss,\n",
    "            dropout=dropout,\n",
    "            **kwargs, # other model params\n",
    "        )\n",
    "\n",
    "        self.loss_func = torch.nn.L1Loss()\n",
    "        self.min_inten = 1e-4\n",
    "\n",
    "    def _get_modloss_frags(self, modloss='modloss'):\n",
    "        self._modloss_frag_types = []\n",
    "        for i,frag in enumerate(self.charged_frag_types):\n",
    "            if modloss in frag:\n",
    "                self._modloss_frag_types.append(i)\n",
    "\n",
    "    def _prepare_train_data_df(self, \n",
    "        precursor_df:pd.DataFrame,\n",
    "        fragment_intensity_df:pd.DataFrame=None,\n",
    "    ):\n",
    "        self.frag_inten_df = fragment_intensity_df[self.charged_frag_types]\n",
    "        # if np.all(precursor_df['nce'].values > 1):\n",
    "        #     precursor_df['nce'] = precursor_df['nce']*self.NCE_factor\n",
    "\n",
    "    def _check_predict_in_order(self, precursor_df: pd.DataFrame):\n",
    "        pass\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "        reference_frag_df:pd.DataFrame=None,\n",
    "    ):\n",
    "        if reference_frag_df is None and precursor_df.nAA.is_monotonic:\n",
    "            self._predict_in_order = True\n",
    "            \n",
    "            if 'frag_start_idx' in precursor_df.columns:\n",
    "                precursor_df.drop(\n",
    "                    columns=['frag_start_idx','frag_end_idx'],\n",
    "                    inplace=True\n",
    "                )\n",
    "        else:\n",
    "            self._predict_in_order = False\n",
    "        \n",
    "        self.predict_df = init_fragment_by_precursor_dataframe(\n",
    "            precursor_df, self.charged_frag_types, \n",
    "            reference_fragment_df=reference_frag_df, \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # if np.all(precursor_df['nce'].values > 1):\n",
    "        #     precursor_df['nce'] = precursor_df['nce']*self.NCE_factor\n",
    "\n",
    "    def _get_features_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame, \n",
    "        **kwargs,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        aa_indices = self._get_26aa_indice_features(batch_df)\n",
    "\n",
    "        mod_x = self._get_mod_features(batch_df)\n",
    "\n",
    "        charges = self._as_tensor(\n",
    "            batch_df['charge'].values\n",
    "        ).unsqueeze(1)*self.charge_factor\n",
    "\n",
    "        nces = self._as_tensor(\n",
    "            batch_df['nce'].values\n",
    "        ).unsqueeze(1)*self.NCE_factor\n",
    "\n",
    "        instrument_indices = self._as_tensor(\n",
    "            parse_instrument_indices(batch_df['instrument']),\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        return aa_indices, mod_x, charges, nces, instrument_indices\n",
    "\n",
    "    def _get_targets_from_batch_df(self, \n",
    "        batch_df: pd.DataFrame,\n",
    "        fragment_intensity_df:pd.DataFrame=None\n",
    "    ) -> torch.Tensor:\n",
    "        return self._as_tensor(\n",
    "            get_sliced_fragment_dataframe(\n",
    "                fragment_intensity_df, \n",
    "                batch_df[\n",
    "                    ['frag_start_idx','frag_end_idx']\n",
    "                ].values\n",
    "            ).values\n",
    "        ).view(-1, \n",
    "            batch_df.nAA.values[0]-1, \n",
    "            len(self.charged_frag_types)\n",
    "        )\n",
    "\n",
    "    def _set_batch_predict_data(self, \n",
    "        batch_df: pd.DataFrame, \n",
    "        predicts:np.ndarray,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        apex_intens = predicts.reshape((len(batch_df), -1)).max(axis=1)\n",
    "        apex_intens[apex_intens<=0] = 1\n",
    "        predicts /= apex_intens.reshape((-1,1,1))\n",
    "        predicts[predicts<self.min_inten] = 0.0\n",
    "        if self._predict_in_order:\n",
    "            self.predict_df.values[\n",
    "                batch_df.frag_start_idx.values[0]:\n",
    "                batch_df.frag_end_idx.values[-1], \n",
    "            :] = predicts.reshape(\n",
    "                    (-1, len(self.charged_frag_types))\n",
    "                )\n",
    "        else:\n",
    "            update_sliced_fragment_dataframe(\n",
    "                self.predict_df,\n",
    "                predicts.reshape(\n",
    "                    (-1, len(self.charged_frag_types))\n",
    "                ),\n",
    "                batch_df[\n",
    "                    ['frag_start_idx','frag_end_idx']\n",
    "                ].values,\n",
    "            )\n",
    "\n",
    "    def train_with_warmup(self,\n",
    "        precursor_df: pd.DataFrame, \n",
    "        fragment_intensity_df, \n",
    "        *, \n",
    "        batch_size=1024, \n",
    "        epoch=10,\n",
    "        warmup_epoch=5,\n",
    "        lr = 1e-5,\n",
    "        verbose=False, \n",
    "        verbose_each_epoch=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return super().train_with_warmup(\n",
    "            precursor_df, \n",
    "            fragment_intensity_df=fragment_intensity_df,\n",
    "            batch_size=batch_size, \n",
    "            epoch=epoch,\n",
    "            warmup_epoch=warmup_epoch,\n",
    "            lr=lr,\n",
    "            verbose=verbose, \n",
    "            verbose_each_epoch=verbose_each_epoch,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def train(self, \n",
    "        precursor_df: pd.DataFrame, \n",
    "        fragment_intensity_df, \n",
    "        *, \n",
    "        batch_size=1024, \n",
    "        epoch=20,\n",
    "        warmup_epoch=0,\n",
    "        lr = 1e-5,\n",
    "        verbose=False, \n",
    "        verbose_each_epoch=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return super().train(\n",
    "            precursor_df, \n",
    "            fragment_intensity_df=fragment_intensity_df,\n",
    "            batch_size=batch_size, \n",
    "            epoch=epoch, \n",
    "            warmup_epoch=warmup_epoch,\n",
    "            lr=lr,\n",
    "            verbose=verbose, \n",
    "            verbose_each_epoch=verbose_each_epoch,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def predict(self, \n",
    "        precursor_df: pd.DataFrame, \n",
    "        *, \n",
    "        batch_size=1024, \n",
    "        verbose=False, \n",
    "        reference_frag_df=None,\n",
    "        **kwargs\n",
    "    ) -> pd.DataFrame:\n",
    "        return super().predict(\n",
    "            precursor_df, \n",
    "            batch_size=batch_size, \n",
    "            verbose=verbose, \n",
    "            reference_frag_df=reference_frag_df, \n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def predict_mp(self, \n",
    "        **kwargs\n",
    "    ) -> pd.DataFrame:\n",
    "        warnings.warn(\n",
    "            \"Please use pretrained_models.ModelManager::predict_all() \"\n",
    "            \"for MS2 prediction with multiprocessing\"\n",
    "        )\n",
    "\n",
    "    def bootstrap_nce_search(self, \n",
    "        psm_df:pd.DataFrame, \n",
    "        fragment_intensity_df:pd.DataFrame,\n",
    "        nce_first=15, nce_last=45, nce_step=3,\n",
    "        instrument = 'Lumos',\n",
    "        charged_frag_types:List = None,\n",
    "        metric = 'PCC>0.9', # or 'median PCC'\n",
    "        max_psm_subset = 3000,\n",
    "        n_bootstrap = 3,\n",
    "        callback = None\n",
    "    ):\n",
    "        nce_list = []\n",
    "        for i in range(n_bootstrap):\n",
    "            nce, instrument = self.grid_nce_search(\n",
    "                psm_df, fragment_intensity_df,\n",
    "                nce_first, nce_last, nce_step,\n",
    "                [instrument],\n",
    "                charged_frag_types,\n",
    "                metric, max_psm_subset, n_bootstrap,\n",
    "                callback\n",
    "            )\n",
    "            nce_list.append(nce)\n",
    "        return np.median(nce_list), instrument\n",
    "\n",
    "    def grid_nce_search(self,\n",
    "        psm_df:pd.DataFrame, \n",
    "        fragment_intensity_df:pd.DataFrame,\n",
    "        nce_first=15, nce_last=45, nce_step=3,\n",
    "        search_instruments = ['Lumos'],\n",
    "        charged_frag_types:List = None,\n",
    "        metric = 'PCC>0.9', # or 'median PCC'\n",
    "        max_psm_subset = 1000000,\n",
    "        callback = None\n",
    "    ):\n",
    "        if len(psm_df) > max_psm_subset:\n",
    "            psm_df = psm_df.sample(max_psm_subset).copy()\n",
    "        best_pcc = -1\n",
    "        best_nce = 0.\n",
    "        best_instrument = None\n",
    "        if 'median' in metric:\n",
    "            metric_row = '50%'\n",
    "        else:\n",
    "            metric_row = '>0.90'\n",
    "        search_instruments = set([\n",
    "            settings['model_mgr']['instrument_group'][inst]\n",
    "            for inst in search_instruments\n",
    "        ])\n",
    "        for inst in search_instruments:\n",
    "            for nce in np.arange(nce_first, nce_last+nce_step, nce_step):\n",
    "                psm_df['nce'] = nce\n",
    "                psm_df['instrument'] = inst\n",
    "                predict_inten_df = self.predict(\n",
    "                    psm_df, \n",
    "                    reference_frag_df=fragment_intensity_df\n",
    "                )\n",
    "                df, metrics = calc_ms2_similarity(\n",
    "                    psm_df,\n",
    "                    predict_inten_df, \n",
    "                    fragment_intensity_df,\n",
    "                    charged_frag_types=charged_frag_types,\n",
    "                    metrics=['PCC']\n",
    "                )\n",
    "                pcc = metrics.loc[metric_row, 'PCC']\n",
    "                if pcc > best_pcc:\n",
    "                    best_pcc = pcc\n",
    "                    best_nce = nce\n",
    "                    best_instrument = inst\n",
    "        return best_nce, best_instrument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def normalize_training_intensities(\n",
    "    train_df:pd.DataFrame, \n",
    "    frag_intensity_df:pd.DataFrame\n",
    ")->Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Normalize the intensities to 0-1 values for MS2 model training.\n",
    "    This will remove fragments not corresponded to the train_df (psm_df),\n",
    "    and generate a new psm_df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pd.DataFrame\n",
    "        training psm dataframe\n",
    "        \n",
    "    frag_intensity_df : pd.DataFrame\n",
    "        training intensity dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        normalized training psm dataframe \n",
    "        which is different from train_df\n",
    "\n",
    "    pd.DataFrame\n",
    "        normalized training intensity dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    new_frag_intens_list = []\n",
    "    new_frag_lens = []\n",
    "    for i, (frag_start_idx, frag_end_idx) in enumerate(\n",
    "        train_df[['frag_start_idx','frag_end_idx']].values\n",
    "    ):\n",
    "        intens = frag_intensity_df.values[frag_start_idx:frag_end_idx]\n",
    "        new_frag_lens.append(len(intens))\n",
    "        max_inten = np.max(intens)\n",
    "        if max_inten > 0:\n",
    "            intens /= max_inten\n",
    "        new_frag_intens_list.append(intens)\n",
    "    indices = np.zeros(len(new_frag_lens)+1, dtype=np.int64)\n",
    "    indices[1:] = new_frag_lens\n",
    "    indices = np.cumsum(indices)\n",
    "    train_df['frag_start_idx'] = indices[:-1]\n",
    "    train_df['frag_end_idx'] = indices[1:]\n",
    "\n",
    "    frag_df = pd.DataFrame(\n",
    "        data=np.concatenate(new_frag_intens_list, axis=0), \n",
    "        columns=frag_intensity_df.columns\n",
    "    )\n",
    "    return train_df, frag_df\n",
    "\n",
    "def normalize_fragment_intensities_(\n",
    "    psm_df:pd.DataFrame, \n",
    "    frag_intensity_df:pd.DataFrame\n",
    "):\n",
    "    \"\"\"Normalize the intensities inplace\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    psm_df : pd.DataFrame\n",
    "        PSM DataFrame\n",
    "\n",
    "    frag_intensity_df : pd.DataFrame\n",
    "        Fragment intensity DataFrame to be normalized. \n",
    "        Intensities will be normalzied inplace.\n",
    "    \"\"\"\n",
    "    for i, (frag_start_idx, frag_end_idx) in enumerate(\n",
    "        psm_df[['frag_start_idx','frag_end_idx']].values\n",
    "    ):\n",
    "        intens = frag_intensity_df.values[frag_start_idx:frag_end_idx]\n",
    "        max_inten = np.max(intens)\n",
    "        if max_inten > 0:\n",
    "            intens /= max_inten\n",
    "        frag_intensity_df.values[frag_start_idx:frag_end_idx,:] = intens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def pearson_correlation(x:torch.Tensor, y:torch.Tensor):\n",
    "    \"\"\"Compute pearson correlation between 2 batches of 1-D tensors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Shape (Batch, n)\n",
    "\n",
    "    y : torch.Tensor\n",
    "        Shape (Batch, n)\n",
    "\n",
    "    \"\"\"\n",
    "    return torch.cosine_similarity(\n",
    "        x-x.mean(dim=1, keepdim=True),\n",
    "        y-y.mean(dim=1, keepdim=True),\n",
    "        dim = 1\n",
    "    )\n",
    "\n",
    "#legacy\n",
    "pearson=pearson_correlation\n",
    "\n",
    "def spectral_angle(cos):\n",
    "    cos[cos>1] = 1\n",
    "    return 1 - 2 * torch.arccos(cos) / np.pi\n",
    "\n",
    "def _get_ranks(x: torch.Tensor, device) -> torch.Tensor:\n",
    "    sorted_idx = x.argsort(dim=1)\n",
    "    flat_idx = (\n",
    "        sorted_idx+torch.arange(\n",
    "            x.size(0), device=device\n",
    "        ).unsqueeze(1)*x.size(1)\n",
    "    ).flatten()\n",
    "    ranks = torch.zeros_like(flat_idx)\n",
    "    ranks[flat_idx] = torch.arange(\n",
    "        x.size(1), device=device\n",
    "    ).unsqueeze(0).repeat(x.size(0),1).flatten()\n",
    "    ranks = ranks.reshape(x.size())\n",
    "    ranks[x==0] = 0\n",
    "    return ranks\n",
    "\n",
    "def spearman_correlation(x: torch.Tensor, y: torch.Tensor, device):\n",
    "    \"\"\"Compute spearman correlation between 2 batches of 1-D tensors\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : torch.Tensor\n",
    "        Shape (Batch, n)\n",
    "\n",
    "    y : torch.Tensor\n",
    "        Shape (Batch, n)\n",
    "\n",
    "    \"\"\"\n",
    "    x_rank = _get_ranks(x, device)\n",
    "    y_rank = _get_ranks(y, device)\n",
    "    \n",
    "    n = x.size(1)\n",
    "    upper = 6 * torch.sum((x_rank - y_rank).pow(2), dim=1)\n",
    "    down = n * (n ** 2 - 1.0)\n",
    "    return 1.0 - (upper / down)\n",
    "\n",
    "#legacy\n",
    "spearman = spearman_correlation\n",
    "\n",
    "def add_cutoff_metric(\n",
    "    metrics_describ, metrics_df, thres=0.9\n",
    "):\n",
    "    vals = []\n",
    "    for col in metrics_describ.columns.values:\n",
    "        vals.append(metrics_df.loc[metrics_df[col]>thres, col].count()/len(metrics_df))\n",
    "    metrics_describ.loc[f'>{thres:.2f}'] = vals\n",
    "    return metrics_describ\n",
    "\n",
    "def calc_ms2_similarity(\n",
    "    psm_df: pd.DataFrame,\n",
    "    predict_intensity_df: pd.DataFrame,\n",
    "    fragment_intensity_df: pd.DataFrame,\n",
    "    charged_frag_types: List=None,\n",
    "    metrics = ['PCC','COS','SA','SPC'],\n",
    "    GPU = True,\n",
    "    batch_size=10240,\n",
    "    verbose=False,\n",
    "    spc_top_k=0,\n",
    ")->Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if GPU:\n",
    "        device, _ = get_available_device()\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    if charged_frag_types is None or len(charged_frag_types)==0:\n",
    "        charged_frag_types = fragment_intensity_df.columns.values\n",
    "\n",
    "    _grouped = psm_df.groupby('nAA')\n",
    "\n",
    "    if verbose:\n",
    "        batch_tqdm = tqdm(_grouped)\n",
    "    else:\n",
    "        batch_tqdm = _grouped\n",
    "\n",
    "    for met in metrics:\n",
    "        psm_df[met] = 0\n",
    "\n",
    "    for nAA, df_group in batch_tqdm:\n",
    "        for i in range(0, len(df_group), batch_size):   \n",
    "            batch_end = i+batch_size\n",
    "            batch_df = df_group.iloc[i:batch_end,:]\n",
    "\n",
    "            pred_intens = torch.tensor(\n",
    "                get_sliced_fragment_dataframe(\n",
    "                    predict_intensity_df, \n",
    "                    batch_df[\n",
    "                        ['frag_start_idx','frag_end_idx']\n",
    "                    ].values,\n",
    "                    charged_frag_types\n",
    "                ).values,\n",
    "                dtype=torch.float32, device=device\n",
    "            ).reshape(\n",
    "                -1, (nAA-1)*len(charged_frag_types)\n",
    "            )\n",
    "\n",
    "            frag_intens = torch.tensor(\n",
    "                get_sliced_fragment_dataframe(\n",
    "                    fragment_intensity_df, \n",
    "                    batch_df[\n",
    "                        ['frag_start_idx','frag_end_idx']\n",
    "                    ].values,\n",
    "                    charged_frag_types\n",
    "                ).values,\n",
    "                dtype=torch.float32, device=device\n",
    "            ).reshape(\n",
    "                -1, (nAA-1)*len(charged_frag_types)\n",
    "            )\n",
    "\n",
    "            if 'PCC' in metrics:\n",
    "                psm_df.loc[batch_df.index,'PCC'] = pearson_correlation(\n",
    "                    pred_intens, frag_intens\n",
    "                ).cpu().detach().numpy()\n",
    "\n",
    "            if 'COS' in metrics or 'SA' in metrics:\n",
    "                cos = torch.cosine_similarity(\n",
    "                    pred_intens, frag_intens, dim=1\n",
    "                )\n",
    "                psm_df.loc[\n",
    "                    batch_df.index,'COS'\n",
    "                ] = cos.cpu().detach().numpy()\n",
    "                \n",
    "                if 'SA' in metrics:\n",
    "                    psm_df.loc[\n",
    "                        batch_df.index,'SA'\n",
    "                    ] = spectral_angle(\n",
    "                        cos\n",
    "                    ).cpu().detach().numpy()\n",
    "\n",
    "            if 'SPC' in metrics:\n",
    "                if spc_top_k > 1 and spc_top_k < frag_intens.size(1):\n",
    "                    sorted_idx = frag_intens.argsort(dim=1, descending=True)\n",
    "                    flat_idx = (\n",
    "                        sorted_idx[:,:spc_top_k]+torch.arange(\n",
    "                            frag_intens.size(0), dtype=torch.int,\n",
    "                            device=device\n",
    "                        ).unsqueeze(1)*frag_intens.size(1)\n",
    "                    ).flatten()\n",
    "                    pred_intens = pred_intens.flatten()[flat_idx].reshape(\n",
    "                        sorted_idx.size(0),-1\n",
    "                    )\n",
    "                    frag_intens = frag_intens.flatten()[flat_idx].reshape(\n",
    "                        sorted_idx.size(0),-1\n",
    "                    )\n",
    "                psm_df.loc[batch_df.index,'SPC'] = spearman_correlation(\n",
    "                    pred_intens, frag_intens, device\n",
    "                ).cpu().detach().numpy()\n",
    "\n",
    "    metrics_describ = psm_df[metrics].describe()\n",
    "    add_cutoff_metric(metrics_describ, psm_df, thres=0.9)\n",
    "    add_cutoff_metric(metrics_describ, psm_df, thres=0.75)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return psm_df, metrics_describ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>nce</th>\n",
       "      <th>instrument</th>\n",
       "      <th>charge</th>\n",
       "      <th>frag_start_idx</th>\n",
       "      <th>frag_end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence                                               mods mod_sites  \\\n",
       "0  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "1  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "2  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "3  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "4  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "5  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "6  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "7  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "8  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "9  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "\n",
       "   nAA  nce instrument  charge  frag_start_idx  frag_end_idx  \n",
       "0   11   20         QE       1               0            10  \n",
       "1   11   20         QE       2              10            20  \n",
       "2   11   20         QE       3              20            30  \n",
       "3   11   20         QE       4              30            40  \n",
       "4   11   20         QE       5              40            50  \n",
       "5   11   20         QE       6              50            60  \n",
       "6   11   20         QE       7              60            70  \n",
       "7   11   20         QE       8              70            80  \n",
       "8   11   20         QE       9              80            90  \n",
       "9   11   20         QE      10              90           100  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragment_intensity_df = pd.DataFrame({\n",
    "    'b':np.arange(100)/100, \n",
    "    'y_modloss':np.arange(100)/100\n",
    "})\n",
    "repeat = 10\n",
    "precursor_df = pd.DataFrame({\n",
    "    'sequence': ['AGHCEWQMKYR']*repeat,\n",
    "    'mods': ['Acetyl@Protein N-term;Carbamidomethyl@C;Oxidation@M']*repeat,\n",
    "    'mod_sites': ['0;4;8']*repeat,\n",
    "    'nAA': [11]*repeat,\n",
    "    'nce': [20]*repeat,\n",
    "    'instrument': 'QE',\n",
    "    'charge': np.arange(1,repeat+1),\n",
    "    'frag_start_idx':np.arange(10, dtype=int)*10,\n",
    "    'frag_end_idx':np.arange(10, dtype=int)*10+10,\n",
    "})\n",
    "precursor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>y_modloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       b  y_modloss\n",
       "0   0.00       0.00\n",
       "1   0.01       0.01\n",
       "2   0.02       0.02\n",
       "3   0.03       0.03\n",
       "4   0.04       0.04\n",
       "..   ...        ...\n",
       "95  0.95       0.95\n",
       "96  0.96       0.96\n",
       "97  0.97       0.97\n",
       "98  0.98       0.98\n",
       "99  0.99       0.99\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fragment_intensity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an MSMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdeep = pDeepModel()\n",
    "pdeep.charged_frag_types=['b','y_modloss']\n",
    "pdeep.build(\n",
    "    ModelMS2pDeep,\n",
    "    num_frag_types = 2,\n",
    "    num_modloss_types = 1,\n",
    "    dropout=0.2,\n",
    "    lr=1e-3\n",
    ")\n",
    "pdeep.train(precursor_df, epoch=5, batch_size=3, fragment_intensity_df=fragment_intensity_df)\n",
    "pdeep.train_with_warmup(precursor_df, epoch=5, batch_size=3, warmup_epoch=3, fragment_intensity_df=fragment_intensity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b            1.0\n",
       "y_modloss    0.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_inten_df = pdeep.predict(precursor_df,reference_frag_df=fragment_intensity_df)\n",
    "predict_inten_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_frag_inten_df = fragment_intensity_df.copy()\n",
    "_frag_inten_df.iloc[0,1] = 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>mods</th>\n",
       "      <th>mod_sites</th>\n",
       "      <th>nAA</th>\n",
       "      <th>nce</th>\n",
       "      <th>instrument</th>\n",
       "      <th>charge</th>\n",
       "      <th>frag_start_idx</th>\n",
       "      <th>frag_end_idx</th>\n",
       "      <th>PCC</th>\n",
       "      <th>COS</th>\n",
       "      <th>SA</th>\n",
       "      <th>SPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.248708</td>\n",
       "      <td>0.735389</td>\n",
       "      <td>0.526001</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AGHCEWQMKYR</td>\n",
       "      <td>Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...</td>\n",
       "      <td>0;4;8</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>QE</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence                                               mods mod_sites  \\\n",
       "0  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "1  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "2  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "3  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "4  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "5  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "6  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "7  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "8  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "9  AGHCEWQMKYR  Acetyl@Protein N-term;Carbamidomethyl@C;Oxidat...     0;4;8   \n",
       "\n",
       "   nAA  nce instrument  charge  frag_start_idx  frag_end_idx       PCC  \\\n",
       "0   11   20         QE       1               0            10  0.248708   \n",
       "1   11   20         QE       2              10            20  1.000000   \n",
       "2   11   20         QE       3              20            30  1.000000   \n",
       "3   11   20         QE       4              30            40  1.000000   \n",
       "4   11   20         QE       5              40            50  1.000000   \n",
       "5   11   20         QE       6              50            60  1.000000   \n",
       "6   11   20         QE       7              60            70  1.000000   \n",
       "7   11   20         QE       8              70            80  1.000000   \n",
       "8   11   20         QE       9              80            90  1.000000   \n",
       "9   11   20         QE      10              90           100  1.000000   \n",
       "\n",
       "        COS        SA  SPC  \n",
       "0  0.735389  0.526001 -1.0  \n",
       "1  1.000000  1.000000  1.0  \n",
       "2  1.000000  1.000000  1.0  \n",
       "3  1.000000  1.000000  1.0  \n",
       "4  1.000000  1.000000  1.0  \n",
       "5  1.000000  1.000000  1.0  \n",
       "6  1.000000  1.000000  1.0  \n",
       "7  1.000000  1.000000  1.0  \n",
       "8  1.000000  1.000000  1.0  \n",
       "9  1.000000  1.000000  1.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, metrics_describ = calc_ms2_similarity(\n",
    "    precursor_df, fragment_intensity_df, \n",
    "    _frag_inten_df, ['b'],\n",
    "    spc_top_k=0\n",
    ")\n",
    "assert df.SPC.values[0] == 1\n",
    "df, metrics_describ = calc_ms2_similarity(\n",
    "    precursor_df, fragment_intensity_df, \n",
    "    _frag_inten_df, ['b','y_modloss'],\n",
    "    spc_top_k=2\n",
    ")\n",
    "assert df.SPC.values[0] == -1\n",
    "precursor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCC</th>\n",
       "      <th>COS</th>\n",
       "      <th>SA</th>\n",
       "      <th>SPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.924871</td>\n",
       "      <td>0.973539</td>\n",
       "      <td>0.952600</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.237579</td>\n",
       "      <td>0.083677</td>\n",
       "      <td>0.149892</td>\n",
       "      <td>0.632455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.248708</td>\n",
       "      <td>0.735389</td>\n",
       "      <td>0.526001</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;0.90</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;0.75</th>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PCC        COS         SA        SPC\n",
       "count  10.000000  10.000000  10.000000  10.000000\n",
       "mean    0.924871   0.973539   0.952600   0.800000\n",
       "std     0.237579   0.083677   0.149892   0.632455\n",
       "min     0.248708   0.735389   0.526001  -1.000000\n",
       "25%     1.000000   1.000000   1.000000   1.000000\n",
       "50%     1.000000   1.000000   1.000000   1.000000\n",
       "75%     1.000000   1.000000   1.000000   1.000000\n",
       "max     1.000000   1.000000   1.000000   1.000000\n",
       ">0.90   0.900000   0.900000   0.900000   0.900000\n",
       ">0.75   0.900000   0.900000   0.900000   0.900000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_describ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 'Lumos')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdeep.grid_nce_search(precursor_df, fragment_intensity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3988974"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdeep = pDeepModel(mask_modloss=False)\n",
    "pdeep.get_parameter_num()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
