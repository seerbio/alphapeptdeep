{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp model.model_interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook mainly defines the basic interface that is used to interact with the deep learning models. Its 'public' functions are intended to stay untouched over the project, while the specific workings of the interface can be changed (i.e. programming polymorphism concept). For example, models can always be loaded with the `load()` function and details of the loading can be changed by inheriting the interface and changing the functions that `load()` calls. More details are given below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.multiprocessing as mp\n",
    "import functools\n",
    "\n",
    "from types import ModuleType\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from typing import IO, Tuple, List, Union\n",
    "from alphabase.yaml_utils import save_yaml, load_yaml\n",
    "from alphabase.peptide.precursor import is_precursor_sorted\n",
    "\n",
    "from peptdeep.settings import model_const\n",
    "from peptdeep.utils import logging, torch_devices, process_bar\n",
    "from peptdeep.settings import global_settings\n",
    "\n",
    "from peptdeep.model.featurize import (\n",
    "    get_ascii_indices, get_batch_aa_indices,\n",
    "    get_batch_mod_feature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# copied from huggingface\n",
    "def get_cosine_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps, \n",
    "    num_training_steps, num_cycles=0.5, \n",
    "    last_epoch=-1\n",
    ") -> LambdaLR:\n",
    "    \"\"\" Create a schedule with a learning rate that decreases following the\n",
    "    values of the cosine function between 0 and `pi * cycles` after a warmup\n",
    "    period during which it increases linearly between 0 and 1.\n",
    "    \"\"\"\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / max(1, num_warmup_steps)\n",
    "        progress = float(\n",
    "            current_step - num_warmup_steps\n",
    "        ) / max(1, num_training_steps - num_warmup_steps)\n",
    "        return max(0.0, 0.5 * (\n",
    "            1.0 + np.cos(np.pi * num_cycles * 2.0 * progress)\n",
    "        ))\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda, last_epoch)\n",
    "\n",
    "def append_nAA_column_if_missing(precursor_df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Append `'nAA'` column containing the number of Amino Acids in each sequence\n",
    "    \"\"\"\n",
    "    if 'nAA' not in precursor_df.columns:\n",
    "        precursor_df['nAA'] = precursor_df.sequence.str.len()\n",
    "        precursor_df.sort_values('nAA', inplace=True)\n",
    "        precursor_df.reset_index(drop=True, inplace=True)\n",
    "    return precursor_df\n",
    "\n",
    "def assign_batches(\n",
    "    df:pd.DataFrame,\n",
    "    *,\n",
    "    split_batches_columns = None,\n",
    "    same_batch_columns = None,\n",
    "    force:bool = False,\n",
    "    batch_size:int = 1024\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Assign objects to batches.\n",
    "\n",
    "    Appends 'batch_index' column to `df` with the assigned DL training batch index.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : required\n",
    "        The table of precursors/peptides.\n",
    "        Each row is one object, columns contain its features.\n",
    "\n",
    "    split_batches_columns : optional\n",
    "        The column(s) in `df` to use for splitting objects into batches.\n",
    "        Rows with nonequal values in `split_batches_columns` will be put\n",
    "        to separate batches.\n",
    "\n",
    "    same_batch_columns : optional\n",
    "        The rows in `df` that have identical values in `split_batches_columns`\n",
    "        and `same_batch_columns` will be kept together in the same batch.\n",
    "        If not specified, no record grouping is done.\n",
    "\n",
    "    batch_size : int\n",
    "        How many objects (rows) each batch should contain.\n",
    "\n",
    "    force : bool\n",
    "        Overwrites the existing `batch_index` column when enabled, skips batch assignment\n",
    "        otherwise. Disabled by default.\n",
    "    \"\"\"\n",
    "    if not force and ('batch_index' in df.columns):\n",
    "        return df # nothing to do\n",
    "\n",
    "    if split_batches_columns is None:\n",
    "        df['batch_index'] = np.floor_divide(range(0, len(df)), batch_size)\n",
    "    else:\n",
    "        cur_batch_index = 0\n",
    "        df['batch_index'] = 0\n",
    "        df_grouped = df.groupby(split_batches_columns)\n",
    "        for batch_id, batches_df in df_grouped:\n",
    "            batch_rows = df_grouped.indices[batch_id]\n",
    "            if same_batch_columns is None:\n",
    "                # when precursors are independent from each other\n",
    "                df.loc[batch_rows, 'batch_index'] = cur_batch_index + np.floor_divide(range(0, len(batches_df)), batch_size)\n",
    "            else:\n",
    "                # assign precusors that have the same values in same_batch_columns to the same batch\n",
    "                cur_batch_size = 0\n",
    "                batches_df_grouped = batches_df.groupby(same_batch_columns)\n",
    "                for atomid, atomic_df in batches_df_grouped:\n",
    "                    atomic_rows = batch_rows[batches_df_grouped.indices[atomid]]\n",
    "                    if cur_batch_size > 0 and cur_batch_size + len(atomic_df) > batch_size:\n",
    "                        # start new batch\n",
    "                        cur_batch_size = 0\n",
    "                        cur_batch_index += 1\n",
    "                    cur_batch_size += len(atomic_df)\n",
    "                    #print(f'#{cur_batch_index}({cur_batch_size}): {atomid} ({atomic_rows})')\n",
    "                    df.loc[atomic_rows, 'batch_index'] = cur_batch_index\n",
    "            cur_batch_index = df.loc[batch_rows[-1], 'batch_index'] + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface Class\n",
    "The `ModelInterface` below is intended to provide a standardized way to handle deep learning models. It does not contain the PyTorch-based models themselves, but provides methods to `load()`, `save()`, `build()`, `train()` and `predict()` new models. These methods are intended to stay unchanged. \n",
    "To adapt the interface to a new usecase, we inherit the interface in a new class and re-implement the relevant method `_get_features_from_batch_df()`. Sometimes we also need to re-implement `_get_targets_from_batch_df()` and `_prepare_predict_data_df()`.\n",
    "\n",
    "The interface will adapt the training and prediction procedures. The implementation below will automatically empty the GPU cache at the end of `train()` and `predict()` to save GPU memory.\n",
    "\n",
    "For example, if we would like to design a new model for peptides with different purposes, for example RT prediction, we need to:\n",
    "\n",
    "- Design the pytorch model (`class RTPrediction(torch.nn.Module):...`).\n",
    "- Design the sub-class inherited from ModelInterface (`class RTPredictionModel(ModelInterface):...`).\n",
    "- In `__init__` method, define `self.target_column_to_train = \"detect_value\"` and `self.target_column_to_predict = \"predict_value\"`. Also define `self._min_pred_value = some_value`.\n",
    "- Re-implement `def _get_features_from_batch_df(self, batch_df): return self._get_aa_indice_features(batch_df)` (default) to predict property for sequence. For modified sequence, use `def _get_features_from_batch_df(self, batch_df): return self._get_aa_mod_features(batch_df)`.\n",
    "\n",
    "- At last, execute the model in a python script or a notebook:\n",
    "```\n",
    "model = RTPredictionModel()\n",
    "model.build(model_class=RTPrediction)\n",
    "df = ... # the training data\n",
    "model.train(df)\n",
    "pred_df = model.predict(df)\n",
    "```\n",
    "\n",
    "Check out `peptdeep.model.generic_property_prediction` for details. `peptdeep.model.rt.AlphaRTModel` and `peptdeep.model.ccs.AlphaCCSModel` are also similar. MS2 prediction model is more complicated as the output value for a peptide is not a scalar value, see `peptdeep.model.ms2.pDeepModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ModelInterface(object):\n",
    "    \"\"\"\n",
    "    Provides standardized methods to interact\n",
    "    with ml models. Inherit into new class and override\n",
    "    the abstract (i.e. not implemented) methods.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        device:str=global_settings['torch_device']['device_type'],\n",
    "        split_batches_columns = 'nAA',\n",
    "        same_batch_columns = None,\n",
    "        target_column_to_predict = None,\n",
    "        target_column_to_train = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.model:torch.nn.Module = None\n",
    "        self.optimizer = None\n",
    "        self.model_params:dict = {}\n",
    "        self.set_device(device)\n",
    "\n",
    "        self._split_batches_columns = split_batches_columns\n",
    "        self._same_batch_columns = same_batch_columns\n",
    "        self._target_column_to_predict = target_column_to_predict\n",
    "        self._target_column_to_train = target_column_to_train\n",
    "        self._min_pred_value = 0.0\n",
    "\n",
    "    @property\n",
    "    def target_column_to_predict(self)->str:\n",
    "        return self._target_column_to_predict\n",
    "\n",
    "    @target_column_to_predict.setter\n",
    "    def target_column_to_predict(self, column:str):\n",
    "        self._target_column_to_predict = column\n",
    "\n",
    "    @property\n",
    "    def target_column_to_train(self)->str:\n",
    "        return self._target_column_to_train\n",
    "\n",
    "    @target_column_to_train.setter\n",
    "    def target_column_to_train(self, column:str):\n",
    "        self._target_column_to_train = column\n",
    "\n",
    "    def set_device(self, \n",
    "        device_type:str = global_settings['torch_device']['device_type'], \n",
    "        device_ids:list = global_settings['torch_device']['device_ids']\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Set the device (e.g. gpu (cuda), mps, cpu, ...) to be used for the model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        device_type : str, optional\n",
    "            Device type, see `torch_device_dict`. \n",
    "            By default global_settings['torch_device']['device_type']\n",
    "\n",
    "        device_ids : list, optional\n",
    "            List of int. Device ids for cuda/gpu (e.g. [1,3] for cuda:1,3). \n",
    "            By default global_settings['torch_device']['device_ids']\n",
    "        \"\"\"\n",
    "        self.device_type = device_type.lower()\n",
    "        self.device_ids = device_ids\n",
    "\n",
    "        if self.device_type not in torch_devices:\n",
    "            self.device_type = 'cpu'\n",
    "        else:\n",
    "            if torch_devices[self.device_type]['is_available']():\n",
    "                self.device_type = torch_devices[self.device_type]['device']\n",
    "            else:\n",
    "                self.device_type = 'cpu'\n",
    "                \n",
    "        if self.device_type == 'cuda' and self.device_ids:\n",
    "            self.device = torch.device(f\"cuda:{','.join([str(_id) for _id in self.device_ids])}\")\n",
    "        else:\n",
    "            self.device = torch.device(self.device_type)\n",
    "        \n",
    "        if self.model is not None:\n",
    "            self.model.to(self.device)\n",
    "\n",
    "    def build(self,\n",
    "        model_class: torch.nn.Module,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Builds the model by specifying the PyTorch module, \n",
    "        the parameters, the device, the loss function ...\n",
    "        \"\"\"\n",
    "        self.model = model_class(**kwargs)\n",
    "        self.model_params = kwargs\n",
    "        self.model.to(self.device)\n",
    "        self._init_for_training()\n",
    "\n",
    "    def train(self,\n",
    "        precursor_df: pd.DataFrame,\n",
    "        *,\n",
    "        epoch=10, \n",
    "        warmup_epoch=0,\n",
    "        lr=1e-4,\n",
    "        batch_size=1024,\n",
    "        force_batches=False,\n",
    "        verbose=False,\n",
    "        verbose_each_epoch=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train the model according to specifications.\n",
    "        \"\"\"\n",
    "        self._prepare_training(precursor_df, lr, **kwargs)\n",
    "        self._prepare_batches(precursor_df, force=force_batches, batch_size=batch_size)\n",
    "\n",
    "        lr_scheduler = self._get_lr_schedule_with_warmup(\n",
    "            warmup_epoch, epoch\n",
    "        ) if warmup_epoch > 0 else \\\n",
    "        LambdaLR(self.optimizer, lambda epoch: lr, -1) # if no warmup, keep constant LR\n",
    "\n",
    "        for epoch in range(epoch):\n",
    "            batch_cost = self._train_one_epoch(\n",
    "                precursor_df, epoch,\n",
    "                verbose_each_epoch,\n",
    "                **kwargs\n",
    "            )\n",
    "            lr_scheduler.step()\n",
    "            if verbose: print(\n",
    "                f'[Training] Epoch={epoch+1}, lr={lr_scheduler.get_last_lr()[0]}, loss={np.mean(batch_cost)}'\n",
    "            )\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def train_with_warmup(self,\n",
    "        precursor_df: pd.DataFrame,\n",
    "        *,\n",
    "        warmup_epoch:int=5,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train the model according to specifications. Includes a warumup \n",
    "        phase with linear increasing and cosine decreasing for lr scheduling).\n",
    "        \"\"\"\n",
    "        self.train(precursor_df, warmup_epoch=warmup_epoch, **kwargs)\n",
    "\n",
    "    def predict(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "        *,\n",
    "        batch_size=1024,\n",
    "        force_batches=False,\n",
    "        verbose:bool=False,\n",
    "        **kwargs\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        The model predicts the properties based on the inputs it has been trained for.\n",
    "        Returns the ouput as a pandas dataframe.\n",
    "        \"\"\"\n",
    "        self._check_predict_in_order(precursor_df)\n",
    "        self._prepare_predict_data_df(precursor_df,**kwargs)\n",
    "        self.model.eval()\n",
    "\n",
    "        self._prepare_batches(precursor_df, force=force_batches, batch_size=batch_size)\n",
    "        batches = precursor_df.groupby('batch_index')\n",
    "        batches_tqdm = tqdm(batches) if verbose else batches\n",
    "        with torch.no_grad():\n",
    "            for batch_ix, batch_df in batches_tqdm:\n",
    "                features = self._get_features_from_batch_df(\n",
    "                    batch_df, **kwargs\n",
    "                )\n",
    "\n",
    "                predicts = self._predict_one_batch(*features) if isinstance(features, tuple) \\\n",
    "                    else self._predict_one_batch(features)\n",
    "\n",
    "                self._set_batch_predict_data(\n",
    "                    batch_df, predicts,\n",
    "                    **kwargs\n",
    "                )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        return self.predict_df\n",
    "\n",
    "    def predict_mp(self,\n",
    "        precursor_df:pd.DataFrame,\n",
    "        *,\n",
    "        mp_batch_size:int=100000,\n",
    "        batch_size=1024,\n",
    "        force_batches=False,\n",
    "        process_num:int=global_settings['thread_num'],\n",
    "        verbose:bool=False,\n",
    "        **kwargs\n",
    "    )->pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Predicting with multiprocessing is no GPUs are availible.\n",
    "        Note this multiprocessing method only works for models those predict\n",
    "        values within (inplace of) the precursor_df.\n",
    "        \"\"\"\n",
    "        self._prepare_batches(precursor_df, force=force_batches, batch_size=batch_size)\n",
    "        # assign mp batches (group together batches to have <= mp_batch_size length)\n",
    "        cur_mpbatch_index = 0\n",
    "        cur_mpbatch_size = 0\n",
    "        precursor_df['mp_batch_index'] = 0\n",
    "        precursor_df_batches = precursor_df.groupby('batch_index')\n",
    "        for batch_ix, batch_df in precursor_df_batches:\n",
    "            if cur_mpbatch_size > 0 and cur_mpbatch_size + len(batch_df) > mp_batch_size:\n",
    "                # start new mpbatch\n",
    "                cur_mpbatch_size = 0\n",
    "                cur_mpbatch_index += 1\n",
    "            cur_mpbatch_size += len(batch_df)\n",
    "            precursor_df.loc[precursor_df_batches.indices[batch_ix], 'mp_batch_index'] = cur_mpbatch_index\n",
    "\n",
    "        if self.device_type != 'cpu':\n",
    "            return self.predict(\n",
    "                precursor_df,\n",
    "                force_batches=False, batch_size=batch_size,\n",
    "                verbose=False,\n",
    "                **kwargs\n",
    "            )\n",
    "            \n",
    "        self._check_predict_in_order(precursor_df)\n",
    "        self._prepare_predict_data_df(precursor_df,**kwargs)\n",
    "\n",
    "        if verbose: print(\"Predicting with multiprocessing ...\")\n",
    "        self.model.share_memory()\n",
    "        df_list = process_bar(mp.Pool(process_num).imap(\n",
    "                    functools.partial(self.predict, verbose=False, **kwargs),\n",
    "                    precursor_df.groupby('mp_batch_index')\n",
    "                ), cur_mpbatch_index\n",
    "            )\n",
    "        self.predict_df = pd.concat(df_list)\n",
    "        self.predict_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        return self.predict_df\n",
    "\n",
    "    def save(self, filename:str):\n",
    "        \"\"\"\n",
    "        Save the model state, the constants used, the code defining the model and the model parameters.\n",
    "        \"\"\"\n",
    "        # TODO save tf.keras.Model\n",
    "        dir = os.path.dirname(filename)\n",
    "        if not dir: dir = './'\n",
    "        if not os.path.exists(dir): os.makedirs(dir)\n",
    "        torch.save(self.model.state_dict(), filename)\n",
    "        with open(filename+'.txt','w') as f: f.write(str(self.model))\n",
    "        save_yaml(filename+'.model_const.yaml', model_const)\n",
    "        self._save_codes(filename+'.model.py')\n",
    "        save_yaml(filename+'.param.yaml', self.model_params)\n",
    "\n",
    "    def load(\n",
    "        self,\n",
    "        model_file: Tuple[str, IO],\n",
    "        model_path_in_zip: str = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Load a model specified in a zip file, a text file or a file stream.\n",
    "        \"\"\"\n",
    "        # TODO load tf.keras.Model\n",
    "        if isinstance(model_file, str):\n",
    "            # We may release all models (msms, rt, ccs, ...) in a single zip file\n",
    "            if model_file.lower().endswith('.zip'):\n",
    "                self._load_model_from_zipfile(model_file, model_path_in_zip)\n",
    "            else:\n",
    "                self._load_model_from_pytorchfile(model_file)\n",
    "        else:\n",
    "            self._load_model_from_stream(model_file)\n",
    "\n",
    "    def get_parameter_num(self):\n",
    "        \"\"\"\n",
    "        Get total number of parameters in model.\n",
    "        \"\"\"\n",
    "        return np.sum([p.numel() for p in self.model.parameters()])\n",
    "\n",
    "    def build_from_py_codes(self,\n",
    "        model_code_file_or_zip:str,\n",
    "        code_file_in_zip:str=None,\n",
    "        include_model_params_yaml:bool=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Build the model based on a python file. Must contain a PyTorch \n",
    "        model implemented as 'class Model(...'\n",
    "        \"\"\"\n",
    "        if model_code_file_or_zip.lower().endswith('.zip'):\n",
    "            with ZipFile(model_code_file_or_zip, 'r') as model_zip:\n",
    "                with model_zip.open(code_file_in_zip,'r') as f:\n",
    "                    codes = f.read()\n",
    "                if include_model_params_yaml:\n",
    "                    with model_zip.open(\n",
    "                        code_file_in_zip[:-len('model.py')]+'param.yaml',\n",
    "                        'r'\n",
    "                    ) as f:\n",
    "                        params = yaml.load(f, yaml.FullLoader)\n",
    "        else:\n",
    "            with open(model_code_file_or_zip, 'r') as f:\n",
    "                codes = f.read()\n",
    "            if include_model_params_yaml:\n",
    "                params = load_yaml(\n",
    "                    model_code_file_or_zip[:-len('model.py')]+'param.yaml'\n",
    "                )\n",
    "\n",
    "        compiled_codes = compile(\n",
    "            codes, \n",
    "            filename='model_file_py',\n",
    "            mode='exec'\n",
    "        )\n",
    "        _module = ModuleType('_apd_nn_codes')\n",
    "        #codes must contains torch model codes 'class Model(...'\n",
    "        exec(compiled_codes, _module.__dict__)\n",
    "\n",
    "        if include_model_params_yaml:\n",
    "            for key, val in params.items():\n",
    "                if key not in kwargs:\n",
    "                    kwargs[key] = val\n",
    "\n",
    "        self.model = _module.Model(**kwargs)\n",
    "        self.model_params = kwargs\n",
    "        self.model.to(self.device)\n",
    "        self._init_for_training()\n",
    "\n",
    "    def _init_for_training(self):\n",
    "        \"\"\"\n",
    "        Set the loss function, and more attributes for different tasks.\n",
    "        The default loss function is nn.L1Loss.\n",
    "        \"\"\"\n",
    "        self.loss_func = torch.nn.L1Loss()\n",
    "\n",
    "    def _as_tensor(self, \n",
    "        data:np.ndarray, \n",
    "        dtype:torch.dtype=torch.float32\n",
    "    )->torch.Tensor:\n",
    "        \"\"\"Convert numerical np.array to pytorch tensor.\n",
    "        The tensor will be stored in self.device\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : np.ndarray\n",
    "            Numerical np.ndarray to be converted as a tensor\n",
    "            \n",
    "        dtype : torch.dtype, optional\n",
    "            The dtype of the indices used for embedding should be `torch.long`. \n",
    "            Defaults to `torch.float32`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The tensor stored in self.device\n",
    "        \"\"\"\n",
    "        return torch.tensor(data, dtype=dtype, device=self.device)\n",
    "\n",
    "    def _load_model_from_zipfile(self, model_file, model_path_in_zip):\n",
    "        with ZipFile(model_file) as model_zip:\n",
    "            with model_zip.open(model_path_in_zip,'r') as pt_file:\n",
    "                self._load_model_from_stream(pt_file)\n",
    "\n",
    "    def _load_model_from_pytorchfile(self, model_file):\n",
    "        with open(model_file,'rb') as pt_file:\n",
    "            self._load_model_from_stream(pt_file)\n",
    "\n",
    "    def _load_model_from_stream(self, stream):\n",
    "        (\n",
    "            missing_keys, unexpect_keys \n",
    "        ) = self.model.load_state_dict(torch.load(\n",
    "            stream, map_location=self.device),\n",
    "            strict=False\n",
    "        )\n",
    "        if len(missing_keys) > 0:\n",
    "            logging.warn(f\"nn parameters {missing_keys} are MISSING while loading models in {self.__class__}\")\n",
    "        if len(unexpect_keys) > 0:\n",
    "            logging.warn(f\"nn parameters {unexpect_keys} are UNEXPECTED while loading models in {self.__class__}\")\n",
    "\n",
    "    def _save_codes(self, save_as):\n",
    "        try:\n",
    "            code = '''import torch\\n'''\n",
    "            code += '''import peptdeep.model.building_block as building_block\\n'''\n",
    "            code += '''from peptdeep.model.model_shop import *\\n'''\n",
    "            class_code = inspect.getsource(self.model.__class__)\n",
    "            code += 'class Model' + class_code[class_code.find('('):]\n",
    "            with open(save_as, 'w') as f:\n",
    "                f.write(code)\n",
    "        except (TypeError, ValueError, KeyError) as e:\n",
    "            logging.info(f'Cannot save model source codes: {str(e)}')\n",
    "\n",
    "    def _train_one_epoch(self, \n",
    "        precursor_df:pd.DataFrame,\n",
    "        epoch, verbose_each_epoch, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Training for an epoch\"\"\"\n",
    "        batch_cost = []\n",
    "        precursor_batches = list(precursor_df.sample(frac=1).groupby('batch_index'))\n",
    "        batches_order = np.random.permutation(len(precursor_batches))\n",
    "        batches_order_tqdm = tqdm(batches_order) if verbose_each_epoch else batches_order\n",
    "        for i_batch in batches_order_tqdm:\n",
    "            batch_ix, batch_df = precursor_batches[i_batch]\n",
    "            # batch_df = batch_df.reset_index(drop=True)\n",
    "            targets = self._get_targets_from_batch_df(\n",
    "                batch_df, **kwargs\n",
    "            )\n",
    "            features = self._get_features_from_batch_df(\n",
    "                batch_df, **kwargs\n",
    "            )\n",
    "            batch_cost.append(\n",
    "                self._train_one_batch(targets, *features) if isinstance(features, tuple)\n",
    "                else self._train_one_batch(targets, features)\n",
    "            )\n",
    "\n",
    "            if verbose_each_epoch:\n",
    "                batches_order_tqdm.set_description(\n",
    "                    f'Epoch={epoch+1}, batch={len(batch_cost)}, loss={batch_cost[-1]:.4f}'\n",
    "                )\n",
    "        return batch_cost\n",
    "\n",
    "    def _one_batch_cost(\n",
    "        self,\n",
    "        targets:torch.Tensor,\n",
    "        predictions:torch.Tensor,\n",
    "        *features\n",
    "    ):\n",
    "        \"\"\"Calculate the predictions cost for one batch.\n",
    "           The default implementation calls `loss_func(predictions, targets)`.\n",
    "        \"\"\"\n",
    "        return self.loss_func(predictions, targets)\n",
    "\n",
    "    def _train_one_batch(\n",
    "        self, \n",
    "        targets:torch.Tensor,\n",
    "        *features,\n",
    "    ):\n",
    "        \"\"\"Training for a mini batch\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        cost = self._one_batch_cost(targets, self.model(*features), *features)\n",
    "        cost.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "        self.optimizer.step()\n",
    "        return cost.item()\n",
    "\n",
    "    def _predict_one_batch(self,\n",
    "        *features\n",
    "    ):\n",
    "        \"\"\"Predicting for a mini batch\"\"\"\n",
    "        return self.model(\n",
    "            *features\n",
    "        ).cpu().detach().numpy()\n",
    "\n",
    "    def _get_targets_from_batch_df(self,\n",
    "        batch_df:pd.DataFrame, **kwargs,\n",
    "    )->torch.Tensor:\n",
    "        \"\"\"Tell the `train()` method how to get target values from the `batch_df`.\n",
    "           All sub-classes must re-implement this method.\n",
    "           Use torch.tensor(np.array, dtype=..., device=self.device) to convert tensor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_df : pd.DataFrame\n",
    "            Dataframe of each mini batch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Target value tensor\n",
    "        \"\"\"\n",
    "        return self._as_tensor(\n",
    "            batch_df[self.target_column_to_train].values, \n",
    "            dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    def _get_aa_indice_features(\n",
    "        self, batch_df:pd.DataFrame\n",
    "    )->torch.LongTensor:\n",
    "        \"\"\"\n",
    "        Get indices values for 128 ascii codes.\n",
    "        \"\"\"\n",
    "        return self._as_tensor(\n",
    "            get_ascii_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def _get_26aa_indice_features(\n",
    "        self, batch_df:pd.DataFrame\n",
    "    )->torch.LongTensor:\n",
    "        \"\"\"\n",
    "        Get indices values for 26 upper-case letters (amino acids), \n",
    "        from 1 to 26. 0 is used for padding.\n",
    "        \"\"\"\n",
    "        return self._as_tensor(\n",
    "            get_batch_aa_indices(\n",
    "                batch_df['sequence'].values.astype('U')\n",
    "            ), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def _get_mod_features(\n",
    "        self, batch_df:pd.DataFrame\n",
    "    )->torch.Tensor:\n",
    "        \"\"\"\n",
    "        Get modification features.\n",
    "        \"\"\"\n",
    "        return self._as_tensor(\n",
    "            get_batch_mod_feature(batch_df)\n",
    "        )\n",
    "\n",
    "    def _get_aa_mod_features(self,\n",
    "        batch_df:pd.DataFrame, **kwargs,\n",
    "    )->Tuple[torch.Tensor]:\n",
    "        return (\n",
    "            self._get_aa_indice_features(batch_df),\n",
    "            self._get_mod_features(batch_df)\n",
    "        )\n",
    "\n",
    "    def _get_features_from_batch_df(self,\n",
    "        batch_df:pd.DataFrame, **kwargs,\n",
    "    )->Union[torch.Tensor, Tuple[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Get input feature tensors of a batch of the precursor dataframe for the model. \n",
    "        This will call `self._get_aa_indice_features(batch_df)` for sequence-level prediciton, \n",
    "        or `self._get_aa_mod_features(batch_df)` for modified sequence-level.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_df : pd.DataFrame\n",
    "            Batch of precursor dataframe.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Union[torch.Tensor, Tuple[torch.Tensor]]: \n",
    "            A feature tensor if call `self._get_aa_indice_features(batch_df)` (default).\n",
    "            Or a tuple of tensors if call `self._get_aa_mod_features(batch_df)`.\n",
    "        \"\"\"\n",
    "        return self._get_aa_indice_features(batch_df)\n",
    "\n",
    "    def _prepare_predict_data_df(self,\n",
    "        precursor_df:pd.DataFrame, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This methods fills 0s in the column of \n",
    "        `self.target_column_to_predict` in `precursor_df`,\n",
    "        and then does `self.predict_df=precursor_df`.\n",
    "        \"\"\"\n",
    "        precursor_df[self.target_column_to_predict] = 0.0\n",
    "        self.predict_df = precursor_df\n",
    "\n",
    "    def _prepare_train_data_df(self,\n",
    "        precursor_df:pd.DataFrame, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Changes to the training dataframe can be implemented here.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        precursor_df : pd.DataFrame\n",
    "            Dataframe containing the training data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _set_batch_predict_data(self,\n",
    "        batch_df:pd.DataFrame,\n",
    "        predict_values:np.ndarray,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Set predicted values into `self.predict_df`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_df : pd.DataFrame\n",
    "            Dataframe of mini batch when predicting\n",
    "\n",
    "        predict_values : np.array\n",
    "            Predicted values\n",
    "        \"\"\"\n",
    "        predict_values[predict_values<self._min_pred_value] = self._min_pred_value\n",
    "        if self._predict_in_order:\n",
    "            self.predict_df.loc[:,self.target_column_to_predict].values[\n",
    "                batch_df.index.values[0]:batch_df.index.values[-1]+1\n",
    "            ] = predict_values\n",
    "        else:\n",
    "            self.predict_df.loc[\n",
    "                batch_df.index,self.target_column_to_predict\n",
    "            ] = predict_values\n",
    "\n",
    "    def _set_optimizer(self, lr):\n",
    "        \"\"\"Set optimizer\"\"\"\n",
    "        self.optimizer = torch.optim.Adam(\n",
    "            self.model.parameters(), lr=lr\n",
    "        )\n",
    "\n",
    "    def set_lr(self, lr:float):\n",
    "        \"\"\"Set learning rate\"\"\"\n",
    "        if self.optimizer is None:\n",
    "            self._set_optimizer(lr)\n",
    "        else:\n",
    "            for g in self.optimizer.param_groups:\n",
    "                g['lr'] = lr\n",
    "\n",
    "    def _get_lr_schedule_with_warmup(self, warmup_epoch, epoch) -> LambdaLR:\n",
    "        if warmup_epoch > epoch:\n",
    "            warmup_epoch = epoch//2\n",
    "        return get_cosine_schedule_with_warmup(\n",
    "            self.optimizer, warmup_epoch, epoch\n",
    "        )\n",
    "\n",
    "    def _prepare_batches(self, precursor_df:pd.DataFrame, **kwargs) -> pd.DataFrame:\n",
    "        return assign_batches(precursor_df,\n",
    "                              split_batches_columns=self._split_batches_columns,\n",
    "                              same_batch_columns=self._same_batch_columns,\n",
    "                              **kwargs)\n",
    "\n",
    "    def _prepare_training(self, precursor_df, lr, **kwargs):\n",
    "        if 'nAA' not in precursor_df.columns:\n",
    "            precursor_df['nAA'] = precursor_df.sequence.str.len()\n",
    "        self._prepare_train_data_df(precursor_df, **kwargs)\n",
    "        self.model.train()\n",
    "\n",
    "        self.set_lr(lr)\n",
    "\n",
    "    def _check_predict_in_order(self, precursor_df:pd.DataFrame):\n",
    "        if is_precursor_sorted(precursor_df):\n",
    "            self._predict_in_order = True\n",
    "        else:\n",
    "            self._predict_in_order = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.set_device\n",
       "\n",
       ">      ModelInterface.set_device (device_type:str='gpu', device_ids:list=[])\n",
       "\n",
       "Set the device (e.g. gpu (cuda), mps, cpu, ...) to be used for the model.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| device_type | str | gpu | Device type, see `torch_device_dict`. <br>By default global_settings['torch_device']['device_type'] |\n",
       "| device_ids | list | [] | List of int. Device ids for cuda/gpu (e.g. [1,3] for cuda:1,3). <br>By default global_settings['torch_device']['device_ids'] |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L103){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.set_device\n",
       "\n",
       ">      ModelInterface.set_device (device_type:str='gpu', device_ids:list=[])\n",
       "\n",
       "Set the device (e.g. gpu (cuda), mps, cpu, ...) to be used for the model.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| device_type | str | gpu | Device type, see `torch_device_dict`. <br>By default global_settings['torch_device']['device_type'] |\n",
       "| device_ids | list | [] | List of int. Device ids for cuda/gpu (e.g. [1,3] for cuda:1,3). <br>By default global_settings['torch_device']['device_ids'] |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.set_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L140){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.build\n",
       "\n",
       ">      ModelInterface.build (model_class:torch.nn.modules.module.Module,\n",
       ">                            **kwargs)\n",
       "\n",
       "Builds the model by specifying the PyTorch module, \n",
       "the parameters, the device, the loss function ..."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L140){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.build\n",
       "\n",
       ">      ModelInterface.build (model_class:torch.nn.modules.module.Module,\n",
       ">                            **kwargs)\n",
       "\n",
       "Builds the model by specifying the PyTorch module, \n",
       "the parameters, the device, the loss function ..."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L187){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.train\n",
       "\n",
       ">      ModelInterface.train (precursor_df:pandas.core.frame.DataFrame,\n",
       ">                            batch_size=1024, epoch=10, warmup_epoch:int=0,\n",
       ">                            lr=0.0001, verbose=False, verbose_each_epoch=False,\n",
       ">                            **kwargs)\n",
       "\n",
       "Train the model according to specifications."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L187){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.train\n",
       "\n",
       ">      ModelInterface.train (precursor_df:pandas.core.frame.DataFrame,\n",
       ">                            batch_size=1024, epoch=10, warmup_epoch:int=0,\n",
       ">                            lr=0.0001, verbose=False, verbose_each_epoch=False,\n",
       ">                            **kwargs)\n",
       "\n",
       "Train the model according to specifications."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L153){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.train_with_warmup\n",
       "\n",
       ">      ModelInterface.train_with_warmup\n",
       ">                                        (precursor_df:pandas.core.frame.DataFra\n",
       ">                                        me, batch_size=1024, epoch=10,\n",
       ">                                        warmup_epoch=5, lr=0.0001,\n",
       ">                                        verbose=False,\n",
       ">                                        verbose_each_epoch=False, **kwargs)\n",
       "\n",
       "Train the model according to specifications. Includes a warumup \n",
       "phase with linear increasing and cosine decreasing for lr scheduling)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L153){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.train_with_warmup\n",
       "\n",
       ">      ModelInterface.train_with_warmup\n",
       ">                                        (precursor_df:pandas.core.frame.DataFra\n",
       ">                                        me, batch_size=1024, epoch=10,\n",
       ">                                        warmup_epoch=5, lr=0.0001,\n",
       ">                                        verbose=False,\n",
       ">                                        verbose_each_epoch=False, **kwargs)\n",
       "\n",
       "Train the model according to specifications. Includes a warumup \n",
       "phase with linear increasing and cosine decreasing for lr scheduling)."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.train_with_warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L225){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.predict\n",
       "\n",
       ">      ModelInterface.predict (precursor_df:pandas.core.frame.DataFrame,\n",
       ">                              batch_size:int=1024, verbose:bool=False,\n",
       ">                              **kwargs)\n",
       "\n",
       "The model predicts the properties based on the inputs it has been trained for.\n",
       "Returns the ouput as a pandas dataframe."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L225){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.predict\n",
       "\n",
       ">      ModelInterface.predict (precursor_df:pandas.core.frame.DataFrame,\n",
       ">                              batch_size:int=1024, verbose:bool=False,\n",
       ">                              **kwargs)\n",
       "\n",
       "The model predicts the properties based on the inputs it has been trained for.\n",
       "Returns the ouput as a pandas dataframe."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L270){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.predict_mp\n",
       "\n",
       ">      ModelInterface.predict_mp (precursor_df:pandas.core.frame.DataFrame,\n",
       ">                                 batch_size:int=1024, mp_batch_size:int=100000,\n",
       ">                                 process_num:int=8, **kwargs)\n",
       "\n",
       "Predicting with multiprocessing is no GPUs are availible.\n",
       "Note this multiprocessing method only works for models those predict\n",
       "values within (inplace of) the precursor_df."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L270){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.predict_mp\n",
       "\n",
       ">      ModelInterface.predict_mp (precursor_df:pandas.core.frame.DataFrame,\n",
       ">                                 batch_size:int=1024, mp_batch_size:int=100000,\n",
       ">                                 process_num:int=8, **kwargs)\n",
       "\n",
       "Predicting with multiprocessing is no GPUs are availible.\n",
       "Note this multiprocessing method only works for models those predict\n",
       "values within (inplace of) the precursor_df."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.predict_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L320){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.save\n",
       "\n",
       ">      ModelInterface.save (filename:str)\n",
       "\n",
       "Save the model state, the constants used, the code defining the model and the model parameters."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L320){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.save\n",
       "\n",
       ">      ModelInterface.save (filename:str)\n",
       "\n",
       "Save the model state, the constants used, the code defining the model and the model parameters."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L334){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.load\n",
       "\n",
       ">      ModelInterface.load (model_file:Tuple[str,IO],\n",
       ">                           model_path_in_zip:str=None, **kwargs)\n",
       "\n",
       "Load a model specified in a zip file, a text file or a file stream."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/MannLabs/alphapeptdeep/blob/main/peptdeep/model/model_interface.py#L334){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ModelInterface.load\n",
       "\n",
       ">      ModelInterface.load (model_file:Tuple[str,IO],\n",
       ">                           model_path_in_zip:str=None, **kwargs)\n",
       "\n",
       "Load a model specified in a zip file, a text file or a file stream."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(ModelInterface.load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the APIs\n",
    "\n",
    "Building a model for peptide classification (e.g. detectability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, design the `torch.nn.Module` (Transformer model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peptdeep.model.building_block as building_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Bert(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "        nlayers = 3,\n",
    "        input_dim = 128, #ascii code number\n",
    "        hidden_dim = 256,\n",
    "        dropout = 0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model based on a transformer Architecture from \n",
    "        Huggingface's BertEncoder class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.input_nn =  torch.nn.Sequential(\n",
    "            torch.nn.Embedding(input_dim, hidden_dim),\n",
    "            building_block.PositionalEncoding(hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.hidden_nn = building_block.Hidden_HFace_Transformer(\n",
    "            hidden_dim, nlayers=nlayers, dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.output_nn = torch.nn.Sequential(\n",
    "            building_block.SeqAttentionSum(hidden_dim),\n",
    "            torch.nn.PReLU(),\n",
    "            self.dropout,\n",
    "            torch.nn.Linear(hidden_dim, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.input_nn(x))\n",
    "\n",
    "        x = self.hidden_nn(x)\n",
    "        x = self.dropout(x[0])\n",
    "\n",
    "        return self.output_nn(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, implement the ModelInterface APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Model(ModelInterface):\n",
    "    def __init__(self, \n",
    "        dropout=0.1,\n",
    "        model_class:torch.nn.Module=Test_Bert, #model class defined above\n",
    "        device:str='gpu',\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(device=device)\n",
    "        self.build(\n",
    "            model_class,\n",
    "            dropout=dropout,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.loss_func = torch.nn.BCELoss() # loss for binary classification\n",
    "        self.target_column_to_predict = 'predicted_prob'\n",
    "        self.target_column_to_train = 'detected_prob'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device `gpu` is not available, set to `cpu`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>detected_prob</th>\n",
       "      <th>nAA</th>\n",
       "      <th>predicted_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABCD</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.79334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence  detected_prob  nAA  predicted_prob\n",
       "0     ABCD            1.0    4         0.79334\n",
       "1     ABCD            1.0    4         0.79334\n",
       "2     ABCD            1.0    4         0.79334\n",
       "3     ABCD            1.0    4         0.79334\n",
       "4     ABCD            1.0    4         0.79334\n",
       "5     ABCD            1.0    4         0.79334\n",
       "6     ABCD            1.0    4         0.79334\n",
       "7     ABCD            1.0    4         0.79334\n",
       "8     ABCD            1.0    4         0.79334\n",
       "9     ABCD            1.0    4         0.79334"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'sequence':['ABCD']*10,\n",
    "})\n",
    "df['detected_prob'] = 1.0\n",
    "\n",
    "model = Test_Model()\n",
    "model.train(df, epoch=2)\n",
    "model.predict(df)\n",
    "assert 'predicted_prob' in df.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `build_from_py_codes()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peptdeep.model.ms2 import pDeepModel\n",
    "from peptdeep.pretrained_models import model_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device `gpu` is not available, set to `cpu`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (input_nn): Input_AA_Mod_PositionalEncoding(\n",
       "    (mod_nn): Mod_Embedding_FixFirstK(\n",
       "      (nn): Linear(in_features=103, out_features=2, bias=False)\n",
       "    )\n",
       "    (aa_emb): Embedding(128, 240, padding_idx=0)\n",
       "    (pos_encoder): PositionalEncoding()\n",
       "  )\n",
       "  (meta_nn): Meta_Embedding(\n",
       "    (nn): Linear(in_features=9, out_features=7, bias=True)\n",
       "  )\n",
       "  (hidden_nn): Hidden_HFace_Transformer(\n",
       "    (bert): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_nn): Decoder_Linear(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (1): PReLU(num_parameters=1)\n",
       "      (2): Linear(in_features=64, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (modloss_nn): ModuleList(\n",
       "    (0): Hidden_HFace_Transformer(\n",
       "      (bert): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder_Linear(\n",
       "      (nn): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=64, bias=True)\n",
       "        (1): PReLU(num_parameters=1)\n",
       "        (2): Linear(in_features=64, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms2_model = pDeepModel()\n",
    "ms2_model.build_from_py_codes(\n",
    "    model_zip, 'generic/ms2.pth.model.py', \n",
    "    include_model_params_yaml=True\n",
    ")\n",
    "\n",
    "ms2_model.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `assign_batches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'batch': [1]*15+[2]*20+[3]*15,\n",
    "    'protein': ['A']*6 + ['B']*6 + ['C']*3 +\n",
    "               ['A']*4 + ['B']*4 + ['C']*4 + ['D']*4 + ['E']*4 +\n",
    "               ['F']*15,\n",
    "    'sequence': ['ABCD']*50,\n",
    "\n",
    "})\n",
    "\n",
    "# simple batch assignment without checking columns\n",
    "assign_batches(df, batch_size=5)\n",
    "assert (df.batch_index == np.repeat(range(0, 10), 5)).all()\n",
    "# don't overwrite existing batches\n",
    "assign_batches(df, batch_size=10)\n",
    "assert (df.batch_index == np.repeat(range(0, 10), 5)).all()\n",
    "# force-overwrite existing batches \n",
    "assign_batches(df, batch_size=10, force=True)\n",
    "assert (df.batch_index == np.repeat(range(0, 5), 10)).all()\n",
    "\n",
    "# split batches by some column\n",
    "assign_batches(df, split_batches_columns='batch', batch_size=100, force=True)\n",
    "assert (df.batch_index == df.batch - 1).all()\n",
    "# split by column and limit batch size\n",
    "assign_batches(df, split_batches_columns='batch', batch_size=8, force=True)\n",
    "assert (df.batch_index == [0]*8 + [1]*7 +[2]*8 + [3]*8 + [4]*4 +[5]*8 + [6]*7).all()\n",
    "# split by column, limit batch size and require that peptides of the same protein are in the same batch\n",
    "assign_batches(df, split_batches_columns='batch', same_batch_columns='protein', batch_size=8, force=True)\n",
    "#with pd.option_context('display.max_rows', None,\n",
    "#                       'display.max_columns', None,\n",
    "#                       'display.precision', 3,\n",
    "#                       ):\n",
    "#    display(df)\n",
    "assert (df.batch_index == [0]*6 + [1]*6 +[2]*3 + [3]*8 + [4]*8 +[5]*4 + [6]*15).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "\n",
    "from peptdeep.pretrained_models import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device `gpu` is not available, set to `cpu`\n",
      "Device `gpu` is not available, set to `cpu`\n",
      "Device `gpu` is not available, set to `cpu`\n",
      "Mac M1 chip ('mps') is not supported yet in pytorch\n",
      "Device `mps` is not available, set to `cpu`\n",
      "Device `gpu` is not available, set to `cpu`\n",
      "Device `cuda` is not available, set to `cpu`\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "model_mgr = ModelManager()\n",
    "model_mgr.ms2_model.set_device('mps')\n",
    "model_mgr.ms2_model.set_device('gpu')\n",
    "model_mgr.ms2_model.set_device('cuda')\n",
    "model_mgr.ms2_model.set_device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
